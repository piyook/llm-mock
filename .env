PROJECT_NAME= llm-mock
SERVER_PORT=8000
LLM_URL_ENDPOINT=chatgpt/chat/completions
## MOCK_LLM_RESPONSE_TYPE can be 'lorem' or 'stored'
MOCK_LLM_RESPONSE_TYPE=stored
MAX_LOREM_PARAS=8
# SET DEBUG TO * START DETAILED DEBUGGING LOGS AND OFF TO STOP
DEBUG=OFF
LLM_NAME=chatgpt
VALIDATE_REQUESTS=ON
# SET LOG_REQUESTS TO ON TO CONSOLE LOG DETAILS OF ALL INCOMING REQUESTS (VALIDATE REQUESTS MUST ALSO BE ON)
LOG_REQUESTS=ON
